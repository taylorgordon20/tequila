{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy.ndimage import filters, zoom\n",
    "from scipy.signal import savgol_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occlusion_map = np.random.choice(a=[False, True], size=(SIZE, SIZE), p=[0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(occlusion_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_map = np.zeros(shape=(SIZE, SIZE), dtype=bool)\n",
    "\n",
    "lights = []\n",
    "num_lights = 10\n",
    "while num_lights:\n",
    "    row, col = np.random.randint(low=0, high=SIZE, size=2)\n",
    "    if occlusion_map[row, col]:\n",
    "        continue\n",
    "    light_map[row, col] = True\n",
    "    lights.append((row, col))\n",
    "    num_lights -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(light_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ray_occlusion_test(start, end):\n",
    "    sx, sy = start\n",
    "    ex, ey = end\n",
    "    steep = abs(ey - sy) > abs(ex - sx)\n",
    "    if steep:\n",
    "        sx, sy = sy, sx\n",
    "        ex, ey = ey, ex\n",
    "    if sx > ex:\n",
    "        sx, ex = ex, sx\n",
    "        sy, ey = ey, sy\n",
    "    dx = ex - sx\n",
    "    dy = ey - sy\n",
    "    df = dy / dx\n",
    "    if dx == 0.0:\n",
    "        return True\n",
    "    for x in [sx, ex] + [ix + 0.5 for ix in range(int(sx + 1), int(ex))]:\n",
    "        ix = int(x)\n",
    "        iy = int(sy + df * (x - sx))\n",
    "        if ix >= occlusion_map.shape[0] or iy >= occlusion_map.shape[1]:\n",
    "            continue\n",
    "        if not steep and occlusion_map[iy, ix]:\n",
    "            return False\n",
    "        elif steep and occlusion_map[ix, iy]:\n",
    "            return False\n",
    "        if ix > sx:\n",
    "            iy = int(sy + df * (ix - sx))\n",
    "            if not steep and occlusion_map[iy, ix]:\n",
    "                return False\n",
    "            elif steep and occlusion_map[ix, iy]:\n",
    "                return False\n",
    "        if ix + 1 < ex:\n",
    "            iy = int(sy + df * (ix + 1 - sx))\n",
    "            if not steep and occlusion_map[iy, ix]:\n",
    "                return False\n",
    "            elif steep and occlusion_map[ix, iy]:\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "RASTER_SIZE = 8\n",
    "ATTENUATION = 1\n",
    "TRUNCATION = 1 / 255.0\n",
    "label_map = np.zeros(shape=(RASTER_SIZE * SIZE, RASTER_SIZE * SIZE), dtype=np.float)\n",
    "\n",
    "# Precompute labels.\n",
    "for row in range(label_map.shape[0]):\n",
    "    for col in range(label_map.shape[1]):\n",
    "        x = col // RASTER_SIZE\n",
    "        y = row // RASTER_SIZE\n",
    "        s = (0.5 + (col % RASTER_SIZE)) / RASTER_SIZE\n",
    "        t = (0.5 + (row % RASTER_SIZE)) / RASTER_SIZE\n",
    "        for light in lights:\n",
    "            eps = 0.01\n",
    "            lx, ly = light[1] + 0.5, light[0] + 0.5\n",
    "            if not ray_occlusion_test((x + s, y + t), (lx, ly)):\n",
    "                continue\n",
    "            irradiance = ATTENUATION / ((x + s - lx)**2 + (y + t - ly)**2)\n",
    "            if irradiance >= TRUNCATION:\n",
    "              label_map[row, col] = max(label_map[row, col], min(1, label_map[row, col] + irradiance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_label_map = filters.gaussian_filter(label_map, sigma = 2.0)\n",
    "plt.imshow(blurred_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_color_map(pixel_map):\n",
    "    color_map = np.zeros(shape=(RASTER_SIZE * SIZE, RASTER_SIZE * SIZE, 3), dtype=np.uint8)\n",
    "\n",
    "    for row in range(label_map.shape[0]):\n",
    "        for col in range(label_map.shape[1]):\n",
    "            x = col // RASTER_SIZE\n",
    "            y = row // RASTER_SIZE\n",
    "            s = (0.5 + (col % RASTER_SIZE)) / RASTER_SIZE\n",
    "            t = (0.5 + (row % RASTER_SIZE)) / RASTER_SIZE\n",
    "            if occlusion_map[y, x]:\n",
    "                color_map[row, col, 0:3] = [255, 0, 0]\n",
    "            else:\n",
    "                color_map[row, col, 0:3] = (pixel_map[row, col] * 255).astype(np.uint8)\n",
    "\n",
    "\n",
    "    for light in lights:\n",
    "        ly, lx = RASTER_SIZE * light[0], RASTER_SIZE * light[1]\n",
    "        for row in range(ly + 2, ly + RASTER_SIZE - 2):\n",
    "            for col in range(lx + 2, lx + RASTER_SIZE - 2):\n",
    "                color_map[row, col] = [0, 0, 255]\n",
    "                \n",
    "    return color_map                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "ax.imshow(make_color_map(blurred_label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clamp(arr, max_norm):\n",
    "    arr_norm = np.linalg.norm(arr)\n",
    "    if arr_norm > max_norm:\n",
    "        return arr / arr_norm * max_norm\n",
    "    else:\n",
    "        return arr\n",
    "\n",
    "def cross_entropy(label, prediction):\n",
    "    return -label * np.log(prediction) - (1 - label) * np.log(1 - prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model:\n",
    "# - A maps vertex light rays onto vertex ray embeddings\n",
    "# - B maps the sum of vertex ray embeddings onto a radiance embedding\n",
    "# - C maps the linear combination of radiance embeddings at a point onto a pixel color\n",
    "# - ray embedding = [1, l_x, l_y, l_z, l_w, l_d, l_d^2 occluded, f_x, f_y, f_z, f_d, f_d^2, o_1, o_2, o_3, o_4]\n",
    "# - A -> s-t interpolate -> B -> add_basis -> color\n",
    "MAX_LIGHTS = 4\n",
    "RADIANCE_DIMENSION = 16\n",
    "LIGHT_DIMENSION = 17\n",
    "BASIS_NUM = 64\n",
    "BASIS_SIZE = RASTER_SIZE\n",
    "\n",
    "# Atlas of pixel maps for a face.\n",
    "basis_map = 0.1 * (np.random.random(size=(BASIS_NUM, BASIS_SIZE, BASIS_SIZE)) - 0.5)\n",
    "\n",
    "A = 0.01 * (np.random.random(size=(RADIANCE_DIMENSION, MAX_LIGHTS * LIGHT_DIMENSION)) - 0.5)\n",
    "B = 0.01 * (np.random.random(size=(RADIANCE_DIMENSION,)) - 0.5)\n",
    "C = 0.01 * (np.random.random(size=(BASIS_NUM, 4 * LIGHT_DIMENSION * MAX_LIGHTS)) - 0.5)\n",
    "\n",
    "# Labels and example weights.\n",
    "pixel_labels = blurred_label_map.copy()\n",
    "pixel_weights = np.absolute(label_map - blurred_label_map)**0.5\n",
    "pixel_weights = 5.0 * np.clip(0.1 + filters.gaussian_filter(pixel_weights, sigma = 2.0), 0, 1)\n",
    "\n",
    "# Learning rates\n",
    "ALPHA_BASE = 0.01\n",
    "ALPHA_DECAY = 0.01\n",
    "ALPHA_FINAL = 0.00001\n",
    "\n",
    "# Gradient clipping\n",
    "MAX_GRAD = 2.0\n",
    "\n",
    "# How many times to loop over each face.\n",
    "LOOP_COUNT = 100\n",
    "\n",
    "# Initialize training state.\n",
    "errors = []\n",
    "ALPHA = ALPHA_BASE\n",
    "iteration = 0\n",
    "face_coords = [(x, y) for x in range(SIZE) for y in range(SIZE) if not occlusion_map[y, x]]\n",
    "\n",
    "ST = np.zeros(shape=(4, RASTER_SIZE, RASTER_SIZE), dtype=np.float32)\n",
    "for p_row in range(RASTER_SIZE):\n",
    "    for p_col in range(RASTER_SIZE):\n",
    "        s = (0.5 + p_col) / RASTER_SIZE\n",
    "        t = (0.5 + p_row) / RASTER_SIZE        \n",
    "        ST[0, p_row, p_col] = (1 - s) * (1 - t)\n",
    "        ST[1, p_row, p_col] = s * (1 - t)\n",
    "        ST[2, p_row, p_col] = (1 - s) * t\n",
    "        ST[3, p_row, p_col] = s * t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "%matplotlib notebook\n",
    "\n",
    "# Create figures.\n",
    "fig1, ax1 = plt.subplots(figsize=(8, 8))\n",
    "fig2, ax2 = plt.subplots(figsize=(8, 3))\n",
    "\n",
    "light_ray_cache = {}\n",
    "\n",
    "def compute_light_ray(x, y, lx, ly, dx, dy):\n",
    "    distance = np.linalg.norm([lx - x, ly - y, 0])\n",
    "    assert distance > 0.01\n",
    "    return [\n",
    "        1,\n",
    "        1.0 / distance**2,\n",
    "        1 if distance < 1 else 0,\n",
    "        1 if distance < 2 else 0,\n",
    "        1 if distance < 4 else 0,\n",
    "        1 if distance < 6 else 0,\n",
    "        1 if distance < 8 else 0,\n",
    "        1 if distance > 1 else 0,\n",
    "        1 if distance > 2 else 0,\n",
    "        1 if distance > 4 else 0,\n",
    "        1 if distance > 6 else 0,\n",
    "        1 if distance > 8 else 0,\n",
    "        occlusion_map[y - 1, x - 1] if y > 0 and x > 0 else 1,\n",
    "        occlusion_map[y - 1, x] if y > 0 and x < occlusion_map.shape[1] - 1 else 1,\n",
    "        occlusion_map[y, x - 1] if y < occlusion_map.shape[0] - 1 and x > 0 else 1,\n",
    "        occlusion_map[y, x] if y < occlusion_map.shape[0] - 1 and x < occlusion_map.shape[1] - 1 else 1,\n",
    "        int(ray_occlusion_test((x, y), (lx, ly))),\n",
    "    ]   \n",
    "\n",
    "\n",
    "def forward_propagation(x, y):\n",
    "    # Cast a ray from each vertex to each light.\n",
    "    if (x, y) not in light_ray_cache:\n",
    "        L1 = np.zeros(shape=MAX_LIGHTS * LIGHT_DIMENSION, dtype=np.float32)\n",
    "        L2 = np.zeros(shape=MAX_LIGHTS * LIGHT_DIMENSION, dtype=np.float32)\n",
    "        L3 = np.zeros(shape=MAX_LIGHTS * LIGHT_DIMENSION, dtype=np.float32)\n",
    "        L4 = np.zeros(shape=MAX_LIGHTS * LIGHT_DIMENSION, dtype=np.float32)\n",
    "        face_lights = sorted(lights, key=lambda l: (l[1] - x)**2 + (l[0] - y)**2)\n",
    "        for i, light in enumerate(face_lights[:MAX_LIGHTS]):\n",
    "            ly, lx = light[0] + 0.5, light[1] + 0.5\n",
    "            ld = LIGHT_DIMENSION\n",
    "            L1[ld * i : ld * (i + 1)] = compute_light_ray(x, y, lx, ly, 1, 1)\n",
    "            L2[ld * i : ld * (i + 1)] = compute_light_ray(x + 1, y, lx, ly, -1, 1)\n",
    "            L3[ld * i : ld * (i + 1)] = compute_light_ray(x, y + 1, lx, ly, 1, -1)\n",
    "            L4[ld * i : ld * (i + 1)] = compute_light_ray(x + 1, y + 1, lx, ly, -1, -1)\n",
    "        light_ray_cache[(x, y)] = (L1, L2, L3, L4)\n",
    "    \n",
    "    L1, L2, L3, L4 = light_ray_cache[(x, y)]\n",
    "\n",
    "    # Map each light ray onto its radiance vector.\n",
    "    r1 = A.dot(L1)\n",
    "    r2 = A.dot(L2)\n",
    "    r3 = A.dot(L3)\n",
    "    r4 = A.dot(L4)\n",
    "\n",
    "    # Generate the predicted face.\n",
    "    R = np.zeros(shape=(RASTER_SIZE, RASTER_SIZE, B.shape[0]), dtype=np.float32)\n",
    "    R += ST[0, :, :, np.newaxis] * r1\n",
    "    R += ST[1, :, :, np.newaxis] * r2\n",
    "    R += ST[2, :, :, np.newaxis] * r3\n",
    "    R += ST[3, :, :, np.newaxis] * r4\n",
    "    T = np.tensordot(R, B, axes=1)\n",
    "    P = np.clip(1.0 / (1 + np.exp(-T)), 0, 1)\n",
    "    \n",
    "    return L1, L2, L3, L4, R, T, P\n",
    "\n",
    "for loop_count in range(LOOP_COUNT):\n",
    "    ALPHA = max(ALPHA_FINAL, ALPHA - ALPHA_DECAY * ALPHA_BASE)\n",
    "    \n",
    "    random.shuffle(face_coords)\n",
    "    for x, y in face_coords:\n",
    "        # Generate a random training example from a random face.\n",
    "        x, y = np.random.randint(low=0, high=SIZE, size=2)\n",
    "        col_s, row_s = x * RASTER_SIZE, y * RASTER_SIZE\n",
    "        col_e, row_e = (x + 1) * RASTER_SIZE, (y + 1) * RASTER_SIZE\n",
    "        L = pixel_labels[row_s : row_e, col_s : col_e]\n",
    "\n",
    "        # Forward progate the model.\n",
    "        L1, L2, L3, L4, R, T, P = forward_propagation(x, y)\n",
    "        \n",
    "        # Compute the back propagation scaling factors.\n",
    "        scale = L - P\n",
    "        \n",
    "        # Compute B gradient.\n",
    "        B_grad = (scale[:, :, np.newaxis] * R).mean(axis=(0, 1))\n",
    "                \n",
    "        # Compute A gradient.\n",
    "        A_grad = np.zeros(shape=A.shape, dtype=np.float32)\n",
    "        A_grad += 0.25 * (scale * ST[0, :, :]).mean() * np.outer(B, L1)\n",
    "        A_grad += 0.25 * (scale * ST[1, :, :]).mean() * np.outer(B, L2)\n",
    "        A_grad += 0.25 * (scale * ST[2, :, :]).mean() * np.outer(B, L3)\n",
    "        A_grad += 0.25 * (scale * ST[3, :, :]).mean() * np.outer(B, L4)\n",
    "        \n",
    "        # Back propagate the model.\n",
    "        B += ALPHA * B_grad\n",
    "        A += ALPHA * A_grad\n",
    "\n",
    "        # Log statistics periodically.\n",
    "        if iteration % 100 == 0 or iteration < 100:\n",
    "            bL = (0.5 + 255 * L).astype(np.uint8)\n",
    "            bP = (0.5 + 255 * P).astype(np.uint8)\n",
    "            errors.append(np.sum((bL - bP)**2))\n",
    "        iteration += 1\n",
    "\n",
    "    # Plot the current lighting of the trained model.\n",
    "    train_map = np.zeros(shape=(RASTER_SIZE * SIZE, RASTER_SIZE * SIZE), dtype=np.float32)\n",
    "    for y in range(SIZE):\n",
    "        for x in range(SIZE):\n",
    "            row_s, row_e = y * RASTER_SIZE, (y + 1) * RASTER_SIZE\n",
    "            col_s, col_e = x * RASTER_SIZE, (x + 1) * RASTER_SIZE\n",
    "            L1, L2, L3, L4, R, T, P = forward_propagation(x, y)\n",
    "            train_map[row_s : row_e, col_s : col_e] = P\n",
    "    ax1.clear()\n",
    "    ax1.imshow(make_color_map(train_map))\n",
    "        \n",
    "    # Plot learning curve.\n",
    "    plot_errors = savgol_filter(errors, min(2 * (len(errors) // 4) + 1, 11), 3)\n",
    "    ax2.clear()\n",
    "    ax2.plot(range(len(plot_errors)), plot_errors, marker=\"\")\n",
    "    \n",
    "    fig1.canvas.draw()\n",
    "    fig2.canvas.draw()\n",
    "    plt.pause(0.05)\n",
    "    print(\n",
    "        \"loop =\", loop_count,\n",
    "        \"ALPHA =\", ALPHA,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
